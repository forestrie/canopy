name: Performance Tests

on:
  # Manual trigger only - select environment and test parameters
  workflow_dispatch:
    inputs:
      environment:
        description: "Target environment"
        required: true
        type: choice
        options:
          - dev
          - prod
        default: dev
      rate:
        description: "Request rate (req/s)"
        required: false
        default: "300"
        type: choice
        options:
          - "10"
          - "25"
          - "50"
          - "100"
          - "110"
          - "150"
          - "250"
          - "300"
          - "400"
          - "800"
          - "1000"
          - "1250"
          - "1500"
          - "1750"
          - "2000"
          - "2500"
          - "3000"
          - "3500"
          - "4000"
      duration:
        description: "Test duration"
        required: false
        default: "3m"
        type: string
      warmup:
        description: "Warmup duration"
        required: false
        default: "30s"
        type: string
      logs_per_shard:
        description: "Logs per shard (uses pre-balanced IDs: 1=4 logs, 2=8 logs, 3=12 logs)"
        required: false
        default: "1"
        type: choice
        options:
          - "1"
          - "2"
          - "3"

permissions:
  contents: read

jobs:
  perf-test:
    name: k6 Performance Test (${{ inputs.environment }}, ${{ matrix.rate }} req/s)
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        rate:
          - ${{ github.event.inputs.rate || '10' }}

    env:
      CANOPY_PERF_API_TOKEN: ${{ secrets.CANOPY_PERF_API_TOKEN }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup k6
        uses: grafana/setup-k6-action@v1

      - name: Load environment config
        id: env_config
        run: |
          ENV=${{ inputs.environment }}
          echo "Loading perf/.env.${ENV}..."
          source perf/.env.${ENV}
          echo "CANOPY_PERF_BASE_URL=${CANOPY_PERF_BASE_URL}" >> $GITHUB_ENV
          echo "FORESTRIE_INGRESS_URL=${FORESTRIE_INGRESS_URL}" >> $GITHUB_ENV
          # Export all log ID variables
          echo "CANOPY_PERF_1LPS_0=${CANOPY_PERF_1LPS_0}" >> $GITHUB_ENV
          echo "CANOPY_PERF_1LPS_1=${CANOPY_PERF_1LPS_1}" >> $GITHUB_ENV
          echo "CANOPY_PERF_1LPS_2=${CANOPY_PERF_1LPS_2}" >> $GITHUB_ENV
          echo "CANOPY_PERF_1LPS_3=${CANOPY_PERF_1LPS_3}" >> $GITHUB_ENV
          echo "CANOPY_PERF_2LPS_0=${CANOPY_PERF_2LPS_0}" >> $GITHUB_ENV
          echo "CANOPY_PERF_2LPS_1=${CANOPY_PERF_2LPS_1}" >> $GITHUB_ENV
          echo "CANOPY_PERF_2LPS_2=${CANOPY_PERF_2LPS_2}" >> $GITHUB_ENV
          echo "CANOPY_PERF_2LPS_3=${CANOPY_PERF_2LPS_3}" >> $GITHUB_ENV
          echo "CANOPY_PERF_2LPS_4=${CANOPY_PERF_2LPS_4}" >> $GITHUB_ENV
          echo "CANOPY_PERF_2LPS_5=${CANOPY_PERF_2LPS_5}" >> $GITHUB_ENV
          echo "CANOPY_PERF_2LPS_6=${CANOPY_PERF_2LPS_6}" >> $GITHUB_ENV
          echo "CANOPY_PERF_2LPS_7=${CANOPY_PERF_2LPS_7}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_0=${CANOPY_PERF_3LPS_0}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_1=${CANOPY_PERF_3LPS_1}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_2=${CANOPY_PERF_3LPS_2}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_3=${CANOPY_PERF_3LPS_3}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_4=${CANOPY_PERF_3LPS_4}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_5=${CANOPY_PERF_3LPS_5}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_6=${CANOPY_PERF_3LPS_6}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_7=${CANOPY_PERF_3LPS_7}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_8=${CANOPY_PERF_3LPS_8}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_9=${CANOPY_PERF_3LPS_9}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_10=${CANOPY_PERF_3LPS_10}" >> $GITHUB_ENV
          echo "CANOPY_PERF_3LPS_11=${CANOPY_PERF_3LPS_11}" >> $GITHUB_ENV
          echo "Environment: ${ENV}"
          echo "Target URL: ${CANOPY_PERF_BASE_URL}"
          echo "Ingress URL: ${FORESTRIE_INGRESS_URL}"

      - name: Build log ID list from balanced sets
        id: log_ids
        run: |
          LOGS_PER_SHARD=${{ github.event.inputs.logs_per_shard || '1' }}
          SHARD_COUNT=4  # Fixed for now
          LOG_COUNT=$((LOGS_PER_SHARD * SHARD_COUNT))
          
          echo "logs_per_shard=$LOGS_PER_SHARD" >> $GITHUB_OUTPUT
          echo "log_count=$LOG_COUNT" >> $GITHUB_OUTPUT

          # Build comma-separated list of log IDs from pre-balanced sets
          LOG_IDS=""
          case $LOGS_PER_SHARD in
            1)
              LOG_IDS="$CANOPY_PERF_1LPS_0,$CANOPY_PERF_1LPS_1,$CANOPY_PERF_1LPS_2,$CANOPY_PERF_1LPS_3"
              ;;
            2)
              LOG_IDS="$CANOPY_PERF_2LPS_0,$CANOPY_PERF_2LPS_1,$CANOPY_PERF_2LPS_2,$CANOPY_PERF_2LPS_3"
              LOG_IDS="$LOG_IDS,$CANOPY_PERF_2LPS_4,$CANOPY_PERF_2LPS_5,$CANOPY_PERF_2LPS_6,$CANOPY_PERF_2LPS_7"
              ;;
            3)
              LOG_IDS="$CANOPY_PERF_3LPS_0,$CANOPY_PERF_3LPS_1,$CANOPY_PERF_3LPS_2,$CANOPY_PERF_3LPS_3"
              LOG_IDS="$LOG_IDS,$CANOPY_PERF_3LPS_4,$CANOPY_PERF_3LPS_5,$CANOPY_PERF_3LPS_6,$CANOPY_PERF_3LPS_7"
              LOG_IDS="$LOG_IDS,$CANOPY_PERF_3LPS_8,$CANOPY_PERF_3LPS_9,$CANOPY_PERF_3LPS_10,$CANOPY_PERF_3LPS_11"
              ;;
          esac

          echo "log_ids=$LOG_IDS" >> $GITHUB_OUTPUT
          echo "Using $LOGS_PER_SHARD log(s) per shard ($LOG_COUNT total): $LOG_IDS"

          # Save log IDs to file for later processing
          echo "$LOG_IDS" > /tmp/log_ids.txt

      - name: Capture queue stats (before)
        id: stats_before
        run: |
          echo "Fetching queue stats before test..."
          STATS=$(curl -s -H "Authorization: Bearer $CANOPY_PERF_API_TOKEN" \
            "${FORESTRIE_INGRESS_URL}/queue/stats")
          echo "stats=$STATS" >> $GITHUB_OUTPUT
          PENDING=$(echo "$STATS" | jq -r '.pending // 0')
          SHARD_COUNT=$(echo "$STATS" | jq -r '.shardCount // 1')
          echo "pending=$PENDING" >> $GITHUB_OUTPUT
          echo "shard_count=$SHARD_COUNT" >> $GITHUB_OUTPUT
          echo "Queue pending before: $PENDING (across $SHARD_COUNT shards)"
          echo "$STATS" | jq -c '.perShard[]? | {shard: .index, pending: .pending, pollers: .activePollers}' 2>/dev/null || true
          date +%s > /tmp/test_start_time

          # Compute and display log-to-shard distribution
          if [ -f /tmp/log_ids.txt ] && [ "$SHARD_COUNT" -gt 0 ]; then
            echo ""
            echo "Log-to-shard distribution (djb2 hash % $SHARD_COUNT):"

            # djb2 hash function (matches @canopy/forestrie-sharding)
            djb2_hash() {
              local str="$1"
              local hash=5381
              for (( i=0; i<${#str}; i++ )); do
                char=$(printf '%d' "'${str:$i:1}")
                hash=$(( ((hash << 5) + hash + char) & 0xFFFFFFFF ))
              done
              echo $(( hash & 0x7FFFFFFF ))
            }

            # Initialize shard counts
            declare -a SHARD_COUNTS
            for (( s=0; s<SHARD_COUNT; s++ )); do
              SHARD_COUNTS[$s]=0
            done

            # Process each log ID
            LOG_IDS=$(cat /tmp/log_ids.txt)
            IFS=',' read -ra IDS <<< "$LOG_IDS"
            DISTRIBUTION=""
            for log_id in "${IDS[@]}"; do
              hash=$(djb2_hash "$log_id")
              shard=$((hash % SHARD_COUNT))
              SHARD_COUNTS[$shard]=$((SHARD_COUNTS[$shard] + 1))
              echo "  $log_id -> shard $shard (hash=$hash)"
              DISTRIBUTION="$DISTRIBUTION$log_id:$shard,"
            done

            # Show summary
            echo ""
            echo "Logs per shard:"
            for (( s=0; s<SHARD_COUNT; s++ )); do
              echo "  shard $s: ${SHARD_COUNTS[$s]} log(s)"
            done

            # Save distribution for summary
            echo "$DISTRIBUTION" > /tmp/log_shard_distribution.txt
          fi

      - name: Run k6 performance test
        id: k6
        env:
          CANOPY_PERF_RATE: ${{ matrix.rate }}
          CANOPY_PERF_DURATION: ${{ github.event.inputs.duration || '3m' }}
          CANOPY_PERF_WARMUP: ${{ github.event.inputs.warmup || '30s' }}
          CANOPY_PERF_SAMPLE_RATE: "0.05"
          CANOPY_PERF_LOG_IDS: ${{ steps.log_ids.outputs.log_ids }}
          CANOPY_PERF_LOG_COUNT: ${{ steps.log_ids.outputs.log_count }}
        run: |
          echo "Running k6 performance test"
          echo "  Rate: ${CANOPY_PERF_RATE} req/s"
          echo "  Duration: ${CANOPY_PERF_DURATION}"
          echo "  Warmup: ${CANOPY_PERF_WARMUP}"
          echo "  Sample rate: ${CANOPY_PERF_SAMPLE_RATE} (for e2e latency)"
          echo "  Log count: ${CANOPY_PERF_LOG_COUNT}"
          echo "  Log IDs: ${CANOPY_PERF_LOG_IDS}"
          echo "  Target: ${CANOPY_PERF_BASE_URL}/logs/.../entries"
          k6 run --no-usage-report perf/k6/canopy-api/scenarios/write-constant-arrival.js

      - name: Capture queue stats (after)
        if: always()
        id: stats_after
        run: |
          echo "Fetching queue stats after test..."
          STATS=$(curl -s -H "Authorization: Bearer $CANOPY_PERF_API_TOKEN" \
            "${FORESTRIE_INGRESS_URL}/queue/stats")
          echo "stats=$STATS" >> $GITHUB_OUTPUT
          PENDING=$(echo "$STATS" | jq -r '.pending // 0')
          echo "pending=$PENDING" >> $GITHUB_OUTPUT
          echo "Queue pending after: $PENDING"
          # Save full stats for per-shard analysis
          echo "$STATS" > /tmp/stats_after.json
          echo "Per-shard breakdown:"
          echo "$STATS" | jq -c '.perShard[]? | {shard: .index, pending: .pending, pollers: .activePollers}' 2>/dev/null || true
          date +%s > /tmp/test_end_time

      - name: Generate job summary
        if: always()
        env:
          PENDING_BEFORE: ${{ steps.stats_before.outputs.pending }}
          PENDING_AFTER: ${{ steps.stats_after.outputs.pending }}
          SHARD_COUNT: ${{ steps.stats_before.outputs.shard_count }}
        run: |
          if [ -f summary.json ]; then
            echo "## üìä k6 Performance Test Results (${{ inputs.environment }})" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Extract config
            BASE_URL=$(jq -r '.config.baseUrl' summary.json)
            LOG_COUNT=$(jq -r '.config.logCount // 1' summary.json)
            LOG_IDS=$(jq -r '.config.logIds // []' summary.json)
            RATE=$(jq -r '.config.rate' summary.json)
            DURATION=$(jq -r '.config.duration' summary.json)
            WARMUP=$(jq -r '.config.warmup' summary.json)

            LOGS_PER_SHARD=${{ steps.log_ids.outputs.logs_per_shard }}
            
            echo "### Configuration" >> $GITHUB_STEP_SUMMARY
            echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Environment | ${{ inputs.environment }} |" >> $GITHUB_STEP_SUMMARY
            echo "| Target URL | \`${BASE_URL}/logs/.../entries\` |" >> $GITHUB_STEP_SUMMARY
            echo "| Logs per shard | ${LOGS_PER_SHARD:-1} |" >> $GITHUB_STEP_SUMMARY
            echo "| Log count | ${LOG_COUNT} |" >> $GITHUB_STEP_SUMMARY
            echo "| Shard count | ${SHARD_COUNT:-4} |" >> $GITHUB_STEP_SUMMARY
            echo "| Target Rate | ${RATE} req/s |" >> $GITHUB_STEP_SUMMARY
            echo "| Duration | ${WARMUP} warmup + ${DURATION} sustained |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Log-to-shard distribution (if multiple shards)
            if [ -f /tmp/log_shard_distribution.txt ] && [ "${SHARD_COUNT:-1}" -gt 1 ]; then
              echo "### Log-to-Shard Distribution" >> $GITHUB_STEP_SUMMARY
              echo "| Log ID | Shard |" >> $GITHUB_STEP_SUMMARY
              echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY

              # Parse distribution file (format: logid:shard,logid:shard,...)
              DIST=$(cat /tmp/log_shard_distribution.txt)
              IFS=',' read -ra PAIRS <<< "$DIST"
              declare -A SHARD_LOG_COUNTS
              for pair in "${PAIRS[@]}"; do
                if [ -n "$pair" ]; then
                  log_id=$(echo "$pair" | cut -d: -f1)
                  shard=$(echo "$pair" | cut -d: -f2)
                  echo "| \`$log_id\` | $shard |" >> $GITHUB_STEP_SUMMARY
                  SHARD_LOG_COUNTS[$shard]=$((${SHARD_LOG_COUNTS[$shard]:-0} + 1))
                fi
              done
              echo "" >> $GITHUB_STEP_SUMMARY

              # Show distribution summary
              echo "**Logs per shard:**" >> $GITHUB_STEP_SUMMARY
              for shard in $(echo "${!SHARD_LOG_COUNTS[@]}" | tr ' ' '\n' | sort -n); do
                echo "- Shard $shard: ${SHARD_LOG_COUNTS[$shard]} log(s)" >> $GITHUB_STEP_SUMMARY
              done

              # Check for imbalance
              TOTAL_LOGS=${LOG_COUNT}
              IDEAL_PER_SHARD=$((TOTAL_LOGS / SHARD_COUNT))
              MAX_LOGS=0
              MIN_LOGS=${TOTAL_LOGS}
              for count in "${SHARD_LOG_COUNTS[@]}"; do
                [ "$count" -gt "$MAX_LOGS" ] && MAX_LOGS=$count
                [ "$count" -lt "$MIN_LOGS" ] && MIN_LOGS=$count
              done
              if [ "$MAX_LOGS" -gt $((IDEAL_PER_SHARD + 1)) ] || [ "$MIN_LOGS" -lt $((IDEAL_PER_SHARD - 1)) ]; then
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "> ‚ö†Ô∏è **Uneven distribution**: Some shards have more logs than others. Consider using different log IDs for better balance." >> $GITHUB_STEP_SUMMARY
              fi
              echo "" >> $GITHUB_STEP_SUMMARY
            fi

            # Extract metrics
            HTTP_COUNT=$(jq -r '.metrics.http_reqs.count // "N/A"' summary.json)
            HTTP_RATE=$(jq -r '.metrics.http_reqs.rate // "N/A"' summary.json)
            ERRORS=$(jq -r '.metrics.post_errors.count // 0' summary.json)

            echo "### Throughput" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Total Requests | ${HTTP_COUNT} |" >> $GITHUB_STEP_SUMMARY
            if [ "$HTTP_RATE" != "N/A" ]; then
              HTTP_RATE_FMT=$(printf "%.2f" "$HTTP_RATE")
              echo "| Achieved Rate | ${HTTP_RATE_FMT} req/s |" >> $GITHUB_STEP_SUMMARY
            fi
            echo "| Errors | ${ERRORS} |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Extract latency
            AVG=$(jq -r '.metrics.post_latency.avg // "N/A"' summary.json)
            MED=$(jq -r '.metrics.post_latency.med // "N/A"' summary.json)
            P90=$(jq -r '.metrics.post_latency.p90 // "N/A"' summary.json)
            P95=$(jq -r '.metrics.post_latency.p95 // "N/A"' summary.json)
            P99=$(jq -r '.metrics.post_latency.p99 // "N/A"' summary.json)
            MAX=$(jq -r '.metrics.post_latency.max // "N/A"' summary.json)

            echo "### POST Latency (time to 303)" >> $GITHUB_STEP_SUMMARY
            echo "| Percentile | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|------------|-------|" >> $GITHUB_STEP_SUMMARY
            if [ "$AVG" != "N/A" ]; then
              AVG_FMT=$(printf "%.0f" "$AVG")
              echo "| avg | ${AVG_FMT} ms |" >> $GITHUB_STEP_SUMMARY
            fi
            if [ "$MED" != "N/A" ]; then
              MED_FMT=$(printf "%.0f" "$MED")
              echo "| p50 (median) | ${MED_FMT} ms |" >> $GITHUB_STEP_SUMMARY
            fi
            if [ "$P90" != "N/A" ]; then
              P90_FMT=$(printf "%.0f" "$P90")
              echo "| p90 | ${P90_FMT} ms |" >> $GITHUB_STEP_SUMMARY
            fi
            if [ "$P95" != "N/A" ]; then
              P95_FMT=$(printf "%.0f" "$P95")
              echo "| p95 | ${P95_FMT} ms |" >> $GITHUB_STEP_SUMMARY
            fi
            if [ "$P99" != "N/A" ]; then
              P99_FMT=$(printf "%.0f" "$P99")
              echo "| p99 | ${P99_FMT} ms |" >> $GITHUB_STEP_SUMMARY
            fi
            if [ "$MAX" != "N/A" ]; then
              MAX_FMT=$(printf "%.0f" "$MAX")
              echo "| max | ${MAX_FMT} ms |" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY

            # Extract e2e latency (sampled)
            E2E_SUCCESS=$(jq -r '.metrics.e2e_success_count // 0' summary.json)
            E2E_TIMEOUTS=$(jq -r '.metrics.e2e_timeout_count // 0' summary.json)
            E2E_TOTAL=$((E2E_SUCCESS + E2E_TIMEOUTS))
            
            if [ "$E2E_TOTAL" -gt 0 ]; then
              # Calculate sample success rate
              if [ "$E2E_SUCCESS" -gt 0 ]; then
                E2E_SUCCESS_RATE=$(echo "scale=1; $E2E_SUCCESS * 100 / $E2E_TOTAL" | bc)
              else
                E2E_SUCCESS_RATE="0"
              fi
              
              echo "### E2E Latency (POST to sequenced)" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              
              # Sample representativeness indicator
              if [ "$E2E_SUCCESS" -gt 10 ] && [ "$E2E_SUCCESS_RATE" != "0" ]; then
                if [ $(echo "$E2E_SUCCESS_RATE >= 50" | bc) -eq 1 ]; then
                  echo "> ‚úÖ **${E2E_SUCCESS}/${E2E_TOTAL} samples** completed (${E2E_SUCCESS_RATE}%) - data is representative" >> $GITHUB_STEP_SUMMARY
                else
                  echo "> ‚ö†Ô∏è **${E2E_SUCCESS}/${E2E_TOTAL} samples** completed (${E2E_SUCCESS_RATE}%) - many timeouts, data may be skewed" >> $GITHUB_STEP_SUMMARY
                fi
              elif [ "$E2E_SUCCESS" -gt 0 ]; then
                echo "> ‚ö†Ô∏è **${E2E_SUCCESS}/${E2E_TOTAL} samples** completed (${E2E_SUCCESS_RATE}%) - limited sample size" >> $GITHUB_STEP_SUMMARY
              else
                echo "> ‚ùå **0/${E2E_TOTAL} samples** completed - all timed out, no latency data" >> $GITHUB_STEP_SUMMARY
              fi
              echo "" >> $GITHUB_STEP_SUMMARY
              
              if [ "$E2E_SUCCESS" -gt 0 ]; then
                E2E_AVG=$(jq -r '.metrics.e2e_latency.avg // "N/A"' summary.json)
                E2E_MED=$(jq -r '.metrics.e2e_latency.med // "N/A"' summary.json)
                E2E_P95=$(jq -r '.metrics.e2e_latency.p95 // "N/A"' summary.json)
                E2E_P99=$(jq -r '.metrics.e2e_latency.p99 // "N/A"' summary.json)
                E2E_MAX=$(jq -r '.metrics.e2e_latency.max // "N/A"' summary.json)

                echo "| Percentile | Value |" >> $GITHUB_STEP_SUMMARY
                echo "|------------|-------|" >> $GITHUB_STEP_SUMMARY
                if [ "$E2E_AVG" != "N/A" ]; then
                  E2E_AVG_FMT=$(printf "%.0f" "$E2E_AVG")
                  echo "| avg | ${E2E_AVG_FMT} ms |" >> $GITHUB_STEP_SUMMARY
                fi
                if [ "$E2E_MED" != "N/A" ]; then
                  E2E_MED_FMT=$(printf "%.0f" "$E2E_MED")
                  echo "| p50 (median) | ${E2E_MED_FMT} ms |" >> $GITHUB_STEP_SUMMARY
                fi
                if [ "$E2E_P95" != "N/A" ]; then
                  E2E_P95_FMT=$(printf "%.0f" "$E2E_P95")
                  echo "| p95 | ${E2E_P95_FMT} ms |" >> $GITHUB_STEP_SUMMARY
                fi
                if [ "$E2E_P99" != "N/A" ]; then
                  E2E_P99_FMT=$(printf "%.0f" "$E2E_P99")
                  echo "| p99 | ${E2E_P99_FMT} ms |" >> $GITHUB_STEP_SUMMARY
                fi
                if [ "$E2E_MAX" != "N/A" ]; then
                  E2E_MAX_FMT=$(printf "%.0f" "$E2E_MAX")
                  echo "| max | ${E2E_MAX_FMT} ms |" >> $GITHUB_STEP_SUMMARY
                fi
                echo "" >> $GITHUB_STEP_SUMMARY
              fi
            fi

            # Sequencing throughput (calculated from queue stats)
            if [ -f /tmp/test_start_time ] && [ -f /tmp/test_end_time ]; then
              START_TIME=$(cat /tmp/test_start_time)
              END_TIME=$(cat /tmp/test_end_time)
              TEST_DURATION=$((END_TIME - START_TIME))

              # Get pending counts from env (set by step outputs)
              QUEUE_BEFORE=${PENDING_BEFORE:-0}
              QUEUE_AFTER=${PENDING_AFTER:-0}

              if [ "$TEST_DURATION" -gt 0 ] && [ "$HTTP_COUNT" != "N/A" ]; then
                # Backlog growth = after - before
                BACKLOG_GROWTH=$((QUEUE_AFTER - QUEUE_BEFORE))

                # Sequenced = total requests - backlog growth
                # (entries that went in and came out during the test)
                HTTP_COUNT_INT=$(printf "%.0f" "$HTTP_COUNT")
                SEQUENCED=$((HTTP_COUNT_INT - BACKLOG_GROWTH))

                # Rates
                SEQ_RATE=$(echo "scale=2; $SEQUENCED / $TEST_DURATION" | bc)
                BACKLOG_RATE=$(echo "scale=2; $BACKLOG_GROWTH / $TEST_DURATION" | bc)

                echo "### Sequencing Throughput (from queue stats)" >> $GITHUB_STEP_SUMMARY
                echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
                echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
                echo "| Queue pending (before) | ${QUEUE_BEFORE} |" >> $GITHUB_STEP_SUMMARY
                echo "| Queue pending (after) | ${QUEUE_AFTER} |" >> $GITHUB_STEP_SUMMARY
                echo "| Backlog growth | ${BACKLOG_GROWTH} |" >> $GITHUB_STEP_SUMMARY
                echo "| Test duration | ${TEST_DURATION}s |" >> $GITHUB_STEP_SUMMARY
                echo "| **Sequencing rate** | **${SEQ_RATE} entries/s** |" >> $GITHUB_STEP_SUMMARY
                echo "| Backlog growth rate | ${BACKLOG_RATE} entries/s |" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY

                # Add interpretation
                if [ "$BACKLOG_GROWTH" -gt 0 ]; then
                  echo "> ‚ö†Ô∏è **Queue building backlog**: Ingress rate exceeds sequencing capacity" >> $GITHUB_STEP_SUMMARY
                elif [ "$BACKLOG_GROWTH" -lt 0 ]; then
                  echo "> ‚úÖ **Queue draining**: Sequencing keeping up with ingress" >> $GITHUB_STEP_SUMMARY
                else
                  echo "> ‚úÖ **Queue stable**: Sequencing matches ingress rate" >> $GITHUB_STEP_SUMMARY
                fi
                echo "" >> $GITHUB_STEP_SUMMARY
              fi
            fi

            # Per-shard breakdown (if stats file exists)
            if [ -f /tmp/stats_after.json ]; then
              SHARD_COUNT_VAL=$(jq -r '.shardCount // 0' /tmp/stats_after.json)
              if [ "$SHARD_COUNT_VAL" -gt 1 ]; then
                echo "### Per-Shard Queue Status (after test)" >> $GITHUB_STEP_SUMMARY
                echo "| Shard | Pending | Active Pollers |" >> $GITHUB_STEP_SUMMARY
                echo "|-------|---------|----------------|" >> $GITHUB_STEP_SUMMARY
                jq -r '.perShard[]? | "| \(.index) | \(.pending) | \(.activePollers) |"' /tmp/stats_after.json >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              fi
            fi

            # Thresholds
            echo "### Thresholds" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Check each threshold (note: thresholds exclude poll_status operations)
            POST_LATENCY_OK=$(jq -r '.thresholds.post_latency["p(99)<5000"] // false' summary.json)
            # Try new key format first, fall back to old format for compatibility
            HTTP_DURATION_P95_OK=$(jq -r '.thresholds["http_req_duration{operation:!poll_status}"]["p(95)<3000"] // .thresholds.http_req_duration["p(95)<3000"] // false' summary.json)
            HTTP_DURATION_P99_OK=$(jq -r '.thresholds["http_req_duration{operation:!poll_status}"]["p(99)<5000"] // .thresholds.http_req_duration["p(99)<5000"] // false' summary.json)
            HTTP_FAILED_OK=$(jq -r '.thresholds["http_req_failed{operation:!poll_status}"]["rate<0.01"] // .thresholds.http_req_failed["rate<0.01"] // false' summary.json)

            if [ "$POST_LATENCY_OK" = "true" ]; then
              echo "- ‚úÖ POST latency p99 < 5000ms" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ‚ùå POST latency p99 < 5000ms" >> $GITHUB_STEP_SUMMARY
            fi

            if [ "$HTTP_DURATION_P95_OK" = "true" ]; then
              echo "- ‚úÖ HTTP duration p95 < 3000ms (excl. polling)" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ‚ùå HTTP duration p95 < 3000ms (excl. polling)" >> $GITHUB_STEP_SUMMARY
            fi

            if [ "$HTTP_DURATION_P99_OK" = "true" ]; then
              echo "- ‚úÖ HTTP duration p99 < 5000ms (excl. polling)" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ‚ùå HTTP duration p99 < 5000ms (excl. polling)" >> $GITHUB_STEP_SUMMARY
            fi

            if [ "$HTTP_FAILED_OK" = "true" ]; then
              echo "- ‚úÖ HTTP failure rate < 1% (excl. polling)" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ‚ùå HTTP failure rate < 1% (excl. polling)" >> $GITHUB_STEP_SUMMARY
            fi

            echo "" >> $GITHUB_STEP_SUMMARY
            echo "_Generated at $(jq -r '.timestamp' summary.json)_" >> $GITHUB_STEP_SUMMARY
          else
            echo "## ‚ö†Ô∏è Performance Test" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "No summary.json file found. Test may have failed before completion." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload summary artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: k6-summary-${{ inputs.environment }}-${{ matrix.rate }}rps
          path: summary.json
          retention-days: 30
          if-no-files-found: ignore
